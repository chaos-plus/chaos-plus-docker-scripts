// ============================================================
// Grafana Alloy 配置文件 - 日志和指标采集
// 功能：
// 1. 采集 Linux 系统指标（CPU、内存、磁盘、网络等）
// 2. 采集 Linux 系统日志
// 3. 采集 Docker 容器日志（仅采集有 logging.enabled=true 标签的容器）
// 4. 提取 trace_id/span_id 用于链路追踪
// 5. 转发日志到 Loki
// 6. 转发指标到 Prometheus
// ============================================================

// ---------------------------
// Linux 系统指标采集
// ---------------------------
// 使用 node_exporter 采集 Linux 系统指标
prometheus.exporter.unix "node" {
  // 禁用不常用的收集器
  disable_collectors = ["ipvs", "btrfs", "infiniband", "xfs", "zfs"]
  
  // 启用内存详细信息收集器
  enable_collectors = ["meminfo"]
  
  // 文件系统配置
  filesystem {
    // 排除虚拟文件系统
    fs_types_exclude = "^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|tmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$"
    
    // 排除特殊挂载点
    mount_points_exclude = "^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)($|/)"
    
    // 挂载点超时
    mount_timeout = "5s"
  }
  
  // 网络类配置
  netclass {
    // 忽略虚拟网络接口
    ignored_devices = "^(veth.*|cali.*|[a-f0-9]{15})$"
  }
  
  // 网络设备配置
  netdev {
    // 排除虚拟网络接口
    device_exclude = "^(veth.*|cali.*|[a-f0-9]{15})$"
  }
}

// 为 node_exporter 指标添加标签
discovery.relabel "node" {
  targets = prometheus.exporter.unix.node.targets
  
  // 设置实例标签为主机名
  rule {
    target_label = "instance"
    replacement  = env("HOSTNAME")
  }
  
  // 设置作业标签
  rule {
    target_label = "job"
    replacement = "integrations/node_exporter"
  }
}

// 抓取 node_exporter 指标
prometheus.scrape "node" {
  targets    = discovery.relabel.node.output
  forward_to = [prometheus.remote_write.prometheus.receiver]
  scrape_interval = "15s"
}

// ---------------------------
// Loki 输出端点配置
// ---------------------------
loki.write "loki" {
  endpoint {
    // 使用环境变量 LOKI_URL，默认值为本地地址
    url = env("LOKI_URL")
    
    // 批处理优化
    batch_wait = "5s"
    batch_size = "1MiB"
    
    // 重试配置
    min_backoff_period = "1s"
    max_backoff_period = "30s"
  }
  
  // 全局标签
  external_labels = {
    cluster = env("HOSTNAME"),
    environment = "production",
  }
}

// ---------------------------
// Prometheus 指标输出配置
// ---------------------------
prometheus.remote_write "prometheus" {
  endpoint {
    url = env("PROMETHEUS_URL")
    
    // 批处理配置
    queue_config {
      capacity = 10000
      max_shards = 50
      min_shards = 1
      max_samples_per_send = 1000
      batch_send_deadline = "5s"
    }
  }
  
  external_labels = {
    cluster = env("HOSTNAME"),
  }
}

// ---------------------------
// Docker 容器发现和过滤
// ---------------------------
discovery.docker "containers" {
  host = "unix:///var/run/docker.sock"
  refresh_interval = "10s"
  
  // 过滤规则：仅发现有 logging.enabled=true 标签的容器
  filter {
    name = "label"
    values = ["logging.enabled=true"]
  }
}

// ---------------------------
// Docker 标签重写规则
// ---------------------------
discovery.relabel "docker_logs" {
  targets = discovery.docker.containers.targets
  
  // 1. 提取容器名称
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex = "/(.*)"
    target_label = "container"
  }
  
  // 2. 提取容器 ID
  rule {
    source_labels = ["__meta_docker_container_id"]
    target_label = "container_id"
  }
  
  // 3. 提取镜像名称
  rule {
    source_labels = ["__meta_docker_container_image"]
    target_label = "image"
  }
  
  // 4. 提取自定义标签：应用名称
  rule {
    source_labels = ["__meta_docker_container_label_app_name"]
    target_label = "app"
  }
  
  // 5. 提取自定义标签：环境
  rule {
    source_labels = ["__meta_docker_container_label_environment"]
    target_label = "environment"
  }
  
  // 6. 提取自定义标签：日志级别
  rule {
    source_labels = ["__meta_docker_container_label_logging_level"]
    target_label = "level"
  }
  
  // 7. 添加 job 标签
  rule {
    source_labels = ["__meta_docker_container_label_app_name"]
    target_label = "job"
  }
  
  // 8. 提取自定义标签：request_id（如果容器有这个标签）
  rule {
    source_labels = ["__meta_docker_container_label_request_id"]
    target_label = "request_id"
  }
  
  // 9. 提取自定义标签：trace_id（如果容器有这个标签）
  rule {
    source_labels = ["__meta_docker_container_label_trace_id"]
    target_label = "trace_id"
  }
  
  // 10. 提取自定义标签：service_name（服务名称）
  rule {
    source_labels = ["__meta_docker_container_label_service_name"]
    target_label = "service_name"
  }
}

// ---------------------------
// 采集 Docker 容器日志
// ---------------------------
loki.source.docker "docker_logs" {
  host = "unix:///var/run/docker.sock"
  targets = discovery.relabel.docker_logs.output
  forward_to = [loki.process.parse_logs.receiver]
  relabel_rules = discovery.relabel.docker_logs.rules
  refresh_interval = "10s"
}

// ---------------------------
// 日志处理管道：提取 trace_id 和 span_id
// ---------------------------
loki.process "parse_logs" {
  // 阶段 1: 提取 trace_id（支持多种格式）
  stage.regex {
    expression = "(?i)trace[-_]?id[=:\\s]+(?P<trace_id>[a-f0-9]{16,32})"
  }
  
  // 阶段 2: 提取 span_id
  stage.regex {
    expression = "(?i)span[-_]?id[=:\\s]+(?P<span_id>[a-f0-9]{8,16})"
  }
  
  // 阶段 3: 提取 request_id（支持多种格式）
  stage.regex {
    expression = "(?i)request[-_]?id[=:\\s]+(?P<request_id>[a-zA-Z0-9-]{8,64})"
  }
  
  // 阶段 4: 提取 correlation_id（关联 ID）
  stage.regex {
    expression = "(?i)correlation[-_]?id[=:\\s]+(?P<correlation_id>[a-zA-Z0-9-]{8,64})"
  }
  
  // 阶段 5: 提取日志级别（如果没有从标签获取）
  stage.regex {
    expression = "(?i)\\[?(?P<level>TRACE|DEBUG|INFO|WARN|ERROR|FATAL)\\]?"
  }
  
  // 阶段 6: 将提取的字段添加为标签
  stage.labels {
    values = {
      trace_id = "",
      span_id = "",
      request_id = "",
      correlation_id = "",
      level = "",
    }
  }
  
  forward_to = [loki.write.loki.receiver]
}

// ---------------------------
// 采集 Linux 系统日志
// ---------------------------

// 方式 1: 采集 systemd journal 日志（推荐）
// 适用于使用 systemd 的 Linux 系统（Ubuntu 16.04+, CentOS 7+）
// 注意：需要 Alloy 容器挂载 /var/log/journal

// 为 systemd journal 日志添加标签
discovery.relabel "journal" {
  targets = []
  
  // 提取 systemd 单元名称
  rule {
    source_labels = ["__journal__systemd_unit"]
    target_label  = "unit"
  }
  
  // 提取启动 ID
  rule {
    source_labels = ["__journal__boot_id"]
    target_label  = "boot_id"
  }
  
  // 提取传输类型
  rule {
    source_labels = ["__journal__transport"]
    target_label  = "transport"
  }
  
  // 提取日志级别
  rule {
    source_labels = ["__journal_priority_keyword"]
    target_label  = "level"
  }
}

// 采集 systemd journal 日志（如果系统支持）
// 取消注释以启用
// loki.source.journal "system" {
//   max_age       = "24h"  // 只采集最近24小时的日志
//   relabel_rules = discovery.relabel.journal.rules
//   forward_to    = [loki.write.loki.receiver]
// }

// 方式 2: 采集文件日志（通用）
// 适用于所有 Linux 系统
local.file_match "system_logs" {
  path_targets = [{
    __address__ = "localhost",
    __path__    = "/var/log/{syslog,messages,*.log}",  // 自动匹配常见日志文件
    instance    = env("HOSTNAME"),
    job         = "integrations/node_exporter",
  }]
}

loki.source.file "system_logs" {
  targets    = local.file_match.system_logs.targets
  forward_to = [loki.write.loki.receiver]
}

// ---------------------------
// 采集应用日志文件（可选）
// ---------------------------
// 注意：这个是用于采集应用写到文件的日志（不是 Docker 容器日志）
// 通常不需要，因为 Docker 容器日志已经通过上面的 loki.source.docker 采集了
// 只有当应用特意把日志写到文件，并且挂载到宿主机时才需要启用

// local.file_match "app_logs" {
//   path_targets = [
//     {
//       __path__ = "/opt/data/**/*.log",
//       job = "app-file-logs",
//       app = "file-logs",
//     },
//   ]
// }

// loki.source.file "app_logs" {
//   targets = local.file_match.app_logs.targets
//   forward_to = [loki.process.parse_logs.receiver]
// }

// ---------------------------
// 自监控：导出 Alloy 自身的指标
// ---------------------------
prometheus.exporter.self "alloy" { }

prometheus.scrape "alloy_metrics" {
  targets = prometheus.exporter.self.alloy.targets
  forward_to = [prometheus.remote_write.prometheus.receiver]
  
  scrape_interval = "15s"
  
  // 添加标签
  clustering {
    enabled = false
  }
}
